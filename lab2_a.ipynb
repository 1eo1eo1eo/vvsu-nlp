{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T00:43:23.006195Z",
     "start_time": "2025-03-15T00:43:20.843675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "from natasha import Doc, Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "filepath: str = \"/Users/levlazutin/code/vvsu-nlp/output.txt\"\n",
    "\n",
    "with open(filepath, \"r\") as file:\n",
    "    text: str = file.read().replace(\"\\n\", \" \")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    tokens: list = []\n",
    "    for token in doc.tokens:\n",
    "        if token.pos == \"PUNCT\" or token.pos == \"NUM\":\n",
    "            continue\n",
    "\n",
    "        token.lemmatize(morph_vocab)\n",
    "        lemma = token.lemma.lower()\n",
    "\n",
    "        if lemma not in stopwords:\n",
    "            tokens.append(lemma)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "preprocessed_text = preprocess_text(text)\n",
    "\n",
    "print(\"preprocessed_text: \", preprocessed_text[:100])"
   ],
   "id": "b8cf82b768cba6cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_text:  ['преступление', 'наказание', 'федор', 'михаилович', 'достоевский', 'смерть', 'спасение', 'родион', 'раскольников', 'это', 'роман', 'петербургский', 'студент', 'родион', 'раскольников', 'бороться', 'великий', 'искушение', 'история', 'человечество', 'вернее', 'сразу', 'это', 'показаться', 'поначалу', 'странный', 'столкнуться', 'предстоять', 'каждый', 'начинать', 'задумываться', 'устройство', 'мир', 'наш', 'место', 'сущность', 'первый', 'искушение', 'стать', 'затем', 'роковой', 'замысел', 'раскольников', 'изложить', 'короткий', 'разговор', 'офицер', 'студент', 'подслушать', 'однажды', 'раскольников', 'трактир', 'речь', 'идти', 'старуха', 'процентщица', 'который', 'слово', 'студент', 'страшно', 'зло', 'скуп', 'накопить', 'огромный', 'состояние', 'весь', 'деньга', 'завещать', 'монастырь', 'вечный', 'помин', 'душа', 'студент', 'говорить', 'проклятый', 'старуха', 'убить', 'ограбить', 'уверять', 'всякий', 'зазор', 'совесть', 'объяснять', 'почему', 'сторона', 'глупый', 'бессмысленный', 'ничтожный', 'злой', 'больной', 'старушонка', 'никто', 'нужный', 'напротив', 'весь', 'вредный', 'который', 'знать', 'жить', 'который']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T00:43:24.781718Z",
     "start_time": "2025-03-15T00:43:23.009005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bag_of_words(text: list[str]) -> list[int]:\n",
    "    vocab_set = set()\n",
    "    for tokens in text:\n",
    "        vocab_set.update(tokens)\n",
    "    vocabulary = sorted(list(vocab_set))\n",
    "\n",
    "    bow_matrix = []\n",
    "    for tokens in text:\n",
    "        row = [0] * len(vocabulary)\n",
    "        for token in tokens:\n",
    "            if token in vocabulary:\n",
    "                j = vocabulary.index(token)\n",
    "                row[j] += 1\n",
    "        bow_matrix.append(row)\n",
    "\n",
    "    return bow_matrix\n",
    "\n",
    "\n",
    "matrix = bag_of_words([preprocessed_text, preprocessed_text])\n",
    "\n",
    "# print(\"\\n--- Bag of Words ---\")\n",
    "# print(\"matrix: \", matrix[:1])\n",
    "# for i, row in enumerate(matrix[:1]):\n",
    "#     print(f\"Документ {i}:\", row)"
   ],
   "id": "84562db7861bc5ff",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T00:43:24.937926Z",
     "start_time": "2025-03-15T00:43:24.794692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_idf(text: list[str]) -> tuple:\n",
    "    \"\"\"\n",
    "    Принимает список списков токенов.\n",
    "    Возвращает:\n",
    "    - vocabulary: список уникальных слов (отсортированных)\n",
    "    - tfidf_matrix: матрицу (число документов) x (число слов),\n",
    "      где [i, j] = TF-IDF слова j в документе i.\n",
    "    \"\"\"\n",
    "    # 1. Собираем словарь\n",
    "    vocab_set = set()\n",
    "    for tokens in text:\n",
    "        vocab_set.update(tokens)\n",
    "    vocabulary = sorted(list(vocab_set))\n",
    "    N = len(text)  # число документов\n",
    "\n",
    "    # 2. Подсчитаем df(t) для каждого слова\n",
    "    df = [0] * len(vocabulary)\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        for tokens in text:\n",
    "            if word in tokens:\n",
    "                df[i] += 1\n",
    "\n",
    "    # 3. Вычислим IDF\n",
    "    idf = [math.log(N / (1 + df[i])) for i in range(len(vocabulary))]\n",
    "\n",
    "    # 4. Собираем TF-IDF матрицу\n",
    "    tfidf_matrix = []\n",
    "    for tokens in text:\n",
    "        total_words = len(tokens)\n",
    "        word_counts = {}\n",
    "        for t in tokens:\n",
    "            word_counts[t] = word_counts.get(t, 0) + 1\n",
    "\n",
    "        row = []\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            tf = word_counts.get(word, 0) / total_words if total_words > 0 else 0\n",
    "            tfidf_value = tf * idf[i]\n",
    "            row.append(tfidf_value)\n",
    "        tfidf_matrix.append(row)\n",
    "\n",
    "    return vocabulary, tfidf_matrix\n",
    "\n",
    "\n",
    "vocab_tfidf, tfidf_matrix = tf_idf(preprocessed_text)\n",
    "print(\"\\n--- TF-IDF ---\")\n",
    "print(\"Словарь:\", vocab_tfidf[:10])\n",
    "print(\"Матрица TF-IDF:\")\n",
    "for i, row in enumerate(tfidf_matrix[:10]):\n",
    "    print(f\"Документ {i}:\", row)\n"
   ],
   "id": "6b3209d7794f597c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF ---\n",
      "Словарь: ['-', '1', '7', '8', '9', 'a', 'c', 'd', 'e', 'f']\n",
      "Матрица TF-IDF:\n",
      "Документ 0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25351202406893186, 0.0, 0.0, 0.08429220877156443, 0.0, 0.0, 0.12070343375368542, 0.0, 0.09352538719943379, 0.0, 0.2685686663268061, 0.09457389098969145, 0.08247568415916456, 0.05570386505083651, 0.1573922870561724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2722669630883656, 0.0, 0.0, 0.0, 0.0, 0.11267201069730304, 0.0, 0.23738025074653155, 0.11238961169541925, 0.0, 0.18169309368279768, 0.0, 0.0, 0.24940103253182344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3164812885381602, 0.2028096192551455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.126374230158213, 0.0, 0.2269773383752595, 0.0, 0.0, 0.0, 0.9909641029979719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0816800889265097, 0.0, 0.12459050341155026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.303451951577632, 0.0, 0.0, 0.1448441205044225, 0.1893155603245511, 0.0, 0.0631871150791065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30443965644776155, 0.0, 0.21557985356819223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11326409401050022, 0.0, 0.14385513115370918, 0.09218619057052067, 0.0, 0.0, 0.09195513684170667, 0.1561828383861984, 0.14865798574047084, 0.0, 0.0, 0.0, 0.11488566378019363, 0.0, 0.0, 0.17994694725635904, 0.06076785278273074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 5: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16900801604595456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3155259338742518, 0.0, 0.0, 0.0, 0.1891477819793829, 0.16495136831832913, 0.11140773010167301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1501956578399757, 0.0, 0.0, 0.0]\n",
      "Документ 6: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10210011115813712, 0.0, 0.0, 0.0, 0.0, 0.25351202406893186, 0.0, 0.0, 0.12643831315734666, 0.0, 0.0, 0.0, 0.0, 0.1402880807991507, 0.0, 0.2014264997451046, 0.0, 0.2474270524774937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 7: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26373440711513346, 0.0, 0.0, 0.0, 0.16858441754312886, 0.0, 0.0, 0.0, 0.0, 0.18705077439886758, 0.21062371693035498, 0.0, 0.1891477819793829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Документ 8: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0680667407720914, 0.0, 0.1038254195096252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08429220877156443, 0.0, 0.27253964052419655, 0.12070343375368542, 0.0, 0.09352538719943379, 0.10531185846517749, 0.0, 0.09457389098969145, 0.08247568415916456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07509782891998786, 0.0, 0.0, 0.0]\n",
      "Документ 9: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21062371693035498, 0.0, 0.0, 0.0, 0.22281546020334603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.332950433099176, 0.0, 0.0]\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
